######METAGENOMIC SEQUENCING: SHORT-READ ASSEMBLY, MAPPING AND MAG RECONSTRUCTION USING ANVI'O#####
###The workflow and code used, except blasts against specific databases, are all part of anvi'o (see the official website for more information): https://anvio.org/ 


###Before starting: put fastq pair-end read files in a folder named 00_RAW and a create a .txt file that contains sample names in the first column, the pathway to R1 files in the second column and the pathway to R2 files in the third column.

conda activate anvio-8

###Step 1: quality control of short-reads using the criteria described by Minoche et al.
mkdir 01_QC
iu-gen-configs samples.txt -o 01_QC
ls 01_QC/
Sample_01.ini
Sample_02.ini
for ini in 01_QC/*.ini; do iu-filter-quality-minoche $ini; done

###Step 2: metagenomic short-read assembly using MEGAHIT
cd 01_QC
cat *R1.fastq > R1.fastq
cat *R2.fastq > R2.fastq
gzip R*.fastq
megahit -1 R1.fastq.gz -2 R2.fastq.gz --min-contig-len 1000 -o /home/pers/concepcion.sanchez-c/temperature/DNA/megahit -t 16 --k-list 21,41,61,81,99
cd ../
cd megahit  
anvi-script-reformat-fasta final.contigs.fa -o contigs.fa --simplify-names --report-file rename.txt

####Step 3: mapping of short reads onto contigs using Bowtie2
cd ../
NUM_THREADS=16
names='D0_1 D0_2 D0_3 D0_4 D0_6 D14_20_1 D14_20_2 D14_20_3 D14_28_1 D14_28_2 D14_28_3 D14_VAR_1 D14_VAR_2 D14_VAR_3 D28_20_1 D28_20_2 D28_20_3 D28_28_1 D28_28_2 D28_28_3 D28_VAR_1 D28_VAR_2 D28_VAR_3'
mkdir 04_MAPPING
bowtie2-build megahit/contigs.fa 04_MAPPING/contigs

for sample in $names
do
bowtie2 --threads $NUM_THREADS -x 04_MAPPING/contigs -1 /home/pers/concepcion.sanchez-c/temperature/DNA/01_QC/${sample}-QUALITY_PASSED_R1.fastq -2 /home/pers/concepcion.sanchez-c/temperature/DNA/01_QC/${sample}-QUALITY_PASSED_R2.fastq --no-unal -S 04_MAPPING/$sample.sam
samtools view -F 4 -bS 04_MAPPING/$sample.sam > 04_MAPPING/$sample-RAW.bam
anvi-init-bam 04_MAPPING/$sample-RAW.bam -o 04_MAPPING/$sample.bam
rm 04_MAPPING/$sample.sam 04_MAPPING/$sample-RAW.bam
done

###Step 4: create a contig database from the contig file
anvi-gen-contigs-database -f /home/pers/concepcion.sanchez-c/temperature/DNA/megahit/contigs.fa -o contigs.db -n 'Temp_MG'

#####Hidden Markov models: utilize multiple default bacterial single-copy core gene collections and identify hits among your genes to those collections using HMMER
anvi-run-hmms -c contigs.db --num-threads 16

####Annotate genes in your contigs database with functions from the NCBIâ€™s Clusters of Orthologus Groups, EBI's pfam database and (previously downloaded)
anvi-setup-ncbi-cogs --cog-version COG20 --cog-data-dir COG_2020 
#anvi-setup-pfams --pfam-version 32.0 --pfam-data-dir Pfam_v32
anvi-run-ncbi-cogs -c contigs.db --cog-data-dir COG_2020 --num-threads 16
anvi-run-pfams -c contigs.db --pfam-data-dir Pfam_v32 --num-threads 16
anvi-run-scg-taxonomy -c contigs.db


####Step 5: Create individual profiles for each sample
names='D0_1 D0_2 D0_3 D0_4 D0_6 D14_20_1 D14_20_2 D14_20_3 D14_28_1 D14_28_2 D14_28_3 D14_VAR_1 D14_VAR_2 D14_VAR_3 D28_20_1 D28_20_2 D28_20_3 D28_28_1 D28_28_2 D28_28_3 D28_VAR_1 D28_VAR_2 D28_VAR_3'
mkdir 05_PROFILES
for sample in $names ; do anvi-profile -c contigs.db -i 04_MAPPING/$sample.bam --sample-name $sample --min-contig-length 1000 --output-dir 05_PROFILES/$sample ; done 

###Step 6: Merge profiles
mv contigs.db 05_PROFILES
cd 05_PROFILES
anvi-merge */PROFILE.db -o SAMPLES-MERGED -c contigs.db --enforce-hierarchical-clustering

###Contig visualization on anvi'o

anvi-interactive -p PROFILE.db -c contigs.db

###Step 7: Binning, MAG reconstruction and refinement. Binning is done manually based on differential. Bins are stored manually using the anvi'o interactive platform (for more information refer to the anvi'o website)
###Bin refinement on the interactive platform to satisfy quality criteria (completion >50% redundancy <10%) (-C name of the bin collection, -b name of the bin):
anvi-refine -p PROFILE.db -c contigs.db -C bins -b Bin_1
###Refined bins are stored manually based on differential coverage and sequence composition using the interactive platform and summarized using:
anvi-summarize -c contigs.db -p PROFILE.db -C bins

source deactivate anvio_env

##The summary generated contains all the relevant information (MAG abundance, completion, redundancy, functional traits annotated with COG and pfam...) that was used in this study. Plots were obtained using GraphPad Prism 9

####Step 7: Annotation of genes of interest in the MAGs: 
#### 7.1 Diamond blast against specific databases (CARD for antibiotic resistance genes, BacMet for metal resistance genes)
###Example for Rhodoferax MAG and the CARD database, the same was done for all bins and databases, previously downloaded into the folder (databases created using diamond makedb)###

###Blast the contig sequences against the database and filter based on aminoacid identity (>60%) and alignment length (>100 aa) - choose best-hit

diamond blastx --db /databases/card.dmnd --query Rhodoferax-contigs.fa --evalue 0.00001 --out /card/card_contigsRhodoferax.txt -p 16 
awk '$3>=60 && $4>=100 {print;} card_contigsRhodoferax.txt > filtered_cardRhodoferax.txt
awk '!x[$1]++' filtered_cardRhodoferax.txt > besthit_cardRhodoferax.txt

########METAGENOMIC SEQUENCING: ARG AND MRG SCREENING IN NON-ASSEMBLED READS######
####Start from quality-filtered reads (step 1 in the previous code)
####Step 2: conversion to fasta
cd 01_QC
for function in *.fastq; do
fastx_toolkit/fastq_to_fasta -i $function -o $function.fasta -Q33
done
mkdir Fasta_File
mv *.fasta Fasta_File

###Step 3: concatenation of forward and reverse reads (without merging)
cd Fasta_File
ls *.fasta > sample_list.txt

while read ligne
do
	sed 's/\(.*\)\(_R\).*/\1/' > liste_names.txt
done < sample_list.txt

nl liste_names.txt | sort --key 2 --unique | cut --fields 2 > liste_unique_names.txt

while read name
do
	cat $name'_R1'.fastq.fasta  $name'_R2'.fastq.fasta > ./$name'concatenated'.fasta
done < liste_noms_uniques.txt

mkdir concatenated
mv concatenated* concatenated

####Step 4: blast against the CARD database (BacMet database was bacmet.dmnd)
for file in *.fasta
do
diamond blastx --db /databases/card.dmnd --query $file --evalue 0.00001 --out /thermal/card_$file -p 16 
done

mkdir card_results
mv card* card_results
cd card_results

for file in *.fasta
do
awk '$3>=60 && $4>=100 {print;} $file > filtered_$file
done

mkdir filtered
mv filtered* filtered
cd filtered

for file in *.fasta
do
awk '!x[$1]++' $file > besthit_$file

####Step 5: abundance analysis using R

###Input: blast results (filtered) in .tsv format (one file per sample). Two columns: gene (gene names and accession numbers) and count (number of hits) Edit on excel as the example:
###"gene"	"count"
###"1"	"gb|AAA25550.1|ARO:3003105|dfrA3"	1
###"2"	"gb|AAA26793|ARO:3003748|oleC"	1

library(dplyr)
library(tidyverse)

###Create tables with unique gene columns per sample (do it individually for each sample):
setwd("CARD")
arg<-read.table(file ="noMPAB1.txt", header = TRUE, sep = "\t")
arg2 <- arg %>% group_by(gene)
arg3 <- arg2 %>% summarise(n = n())
colnames(arg3)<-colnames(arg)
write.table(arg3, "noMPAB2.tsv", sep ="\t")

setwd("../")
filenames<- list.files("CARD", pattern = "*.tsv", full.names=TRUE)
ldf<-lapply(filenames, read.delim, fill=TRUE, header=TRUE)
names(ldf)=str_remove(filenames,"^.*/")
ldf2<-imap_dfr(ldf, ~cbind(.x,sample=.y))
tab2<-pivot_wider(ldf2, names_from=sample, values_from=count, values_fill=0)
write.table(tab2, "arg_counts.txt")

###Gene counts were normalized per sequencing depth and plotted using GraphPad 9


###########################Clustered heatmap########
###Starting point: MAG abundance table obtained from anvi'o (percent of recruitment)

repart <- read.table("mags.txt",head=TRUE, row.names=1)
repart<-t(repart)
scaleyellowred <- paletteer_c("ggthemes::Classic Orange-White-Blue", 10, -1)
pheatmap(mat = repart, clustering_distance_rows="euclidean", clustering_distance_columns="euclidean", treeheight_row = 30, treeheight_col = 30, fontsize_row = 16, fontsize_col = 16,fontsize = 8, scale="column", border_color="black", cutree_rows=2, cutree_cols=2, color = scaleyellowred)


############NMDS and PERMANOVA###########
library(readr)
relab <- read_table("mags.txt")
metadata <- read_table("metadata.txt")  ###metadata include sampling day, condition and replicate
library(vegan)
NMDS <- metaMDS(relab,distance = "bray")
NMDS
NMDS[["points"]]

#Permanova test
adonis2(relab ~ temperature*time, data = metadata)

